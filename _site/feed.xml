<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>scottp.org</title>
    <description>Scott Persinger - personal blog</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Wed, 06 Nov 2019 09:28:09 -0800</pubDate>
    <lastBuildDate>Wed, 06 Nov 2019 09:28:09 -0800</lastBuildDate>
    <generator>Jekyll v3.6.3</generator>

    
      <item>
        <title>Platform migration: personal blog edition</title>
        <description>&lt;p&gt;Every few years I update my blog to a new system, both as a learning opportunity and to avoid getting stuck on something unmaintained. Last time I migrated from &lt;a href=&quot;https://wordpress.com&quot;&gt;Wordpress&lt;/a&gt; to &lt;a href=&quot;https://ghost.org/&quot;&gt;Ghost blog&lt;/a&gt;, and this time I migrated to &lt;a href=&quot;https://jekyllrb.com/&quot;&gt;Jekyll&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Jekyll is a static site generator. All the dynamic page generation happens in a compile step which generates static files for serving to the browser. This results in a very fast site, but doesn’t play so well if you want to easily create, edit, and publish lots of posts. Fortunately I don’t need anything that dynamic, and keeping my posts in source control is a great strategy for long term maintenance.&lt;/p&gt;

&lt;p&gt;Jekyll is roughly one cycle old on the technology curve. It’s into the ‘early majority’ part of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Technology_adoption_life_cycle&quot;&gt;tech adoption cycle&lt;/a&gt;. I assume the innnovators for blogs are React-based systems like &lt;a href=&quot;https://www.gatsbyjs.org/&quot;&gt;Gastby&lt;/a&gt;. But I don’t really need a lot of React-style interactivity. I’m a fan of sticking with the early majority strategy to strike the right balance between innovation benefits and system maturity. This is usually my approach with phones and OS’s - give me the last major release where all the bugs have been worked out!&lt;/p&gt;

&lt;p&gt;I think this is also a good approach in general when picking a new technology stack for an app or service. Taking up the bleeding edge has a lot of risk (go talk to the people on Angular 1) that you pick something that ultimately doesn’t reach a stable level of maturity. But always picking “tried and true” (the late majority stage) often leaves you on an older technology that isn’t innovating anymore.&lt;/p&gt;

&lt;h1 id=&quot;rise-of-the-front-end-developers&quot;&gt;Rise of the front-end developers&lt;/h1&gt;

&lt;p&gt;Static site generators came out of a reaction to the rising complexity of the standard CMS systems (Wordpress, Drupal, etc…). But their theory and rise dovetails with the development of React and the general explosion of front-end development as a truly specialized profession. Much of this world is working to reduce the importance of back-end development and leverage the browser as a first-class app delivery platform.&lt;/p&gt;

&lt;p&gt;I’m intrigued to see how richer “site generator” systems like Gatsby evolve over time. Can they actually introduce richer interactivity and persistent state without dragging the full complexity of back-end engineering into the picture?&lt;/p&gt;

</description>
        <pubDate>Mon, 04 Nov 2019 00:07:56 -0800</pubDate>
        <link>http://localhost:4000/2019/11/04/now-hosting-with-jekyll/</link>
        <guid isPermaLink="true">http://localhost:4000/2019/11/04/now-hosting-with-jekyll/</guid>
      </item>
    
      <item>
        <title>AWS is a 1000 piece lego kit</title>
        <description>&lt;p&gt;I’ve been spending time lately trying to get a deeper understanding of the current world of AWS. That platform grows and changes so quickly that it takes real effort just to keep up!&lt;/p&gt;

&lt;p&gt;The breadth of AWS is pretty incredible:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Elastic compute&lt;/li&gt;
  &lt;li&gt;Networking services&lt;/li&gt;
  &lt;li&gt;File storage&lt;/li&gt;
  &lt;li&gt;Data storage and data services&lt;/li&gt;
  &lt;li&gt;Messaging and event stream services&lt;/li&gt;
  &lt;li&gt;Developer tools and services&lt;/li&gt;
  &lt;li&gt;Security tools&lt;/li&gt;
  &lt;li&gt;Metrics and monitoring&lt;/li&gt;
  &lt;li&gt;Business applications&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Just wrapping your head around all these services is a challenge. Then trying to build a mental model of how these services fit together and how you might leverage them for your work is a whole project unto itself - if not a whole career.&lt;/p&gt;

&lt;p&gt;AWS these days reminds me of a modern-day, 1000 piece Lego set. Back when I was a kid there were like 10 different lego pieces. That was it! You built everything from this small set of interchangeable blocks.&lt;/p&gt;

&lt;p&gt;But somewhere along the way Lego mastered bespoke lego-piece engineering and brand licensing.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3-us-west-1.amazonaws.com/assets-scottp-org/2017/08/millennium.jpg&quot; alt=&quot;millennium&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The result are lego sets comprising hundreds of specialized pieces. Once one of my kids received a 976 piece lego set from his grandmother. He was so excited that while I was out of the room he set about opening &lt;strong&gt;every single&lt;/strong&gt; bag of pieces in the box and dumping them all out of the floor! Woe betide the parent who has to assemble a thousand random lego pieces into a recognizable structure!&lt;/p&gt;

&lt;p&gt;And this is what AWS reminds me of today. Not because many of the services don’t have important, unique features. For sure they do. The problem is, how do I know which ones to use for my particular problem?&lt;/p&gt;

&lt;p&gt;Should I use Mysql, Mariadb, or Aurora?&lt;/p&gt;

&lt;p&gt;I need to dispatch some background jobs. Should I use SQS or Kinesis? In the past I’ve used Redis for lightweight queuing so maybe I should just use Elasticache?&lt;/p&gt;

&lt;p&gt;Hmm… I just want to deploy a new app. Should I use Lightsail and just do it by hand? Or maybe Elastic Beanstalk - it’s designed for that (although it seems to have fallen into disrepair). Or should I go with the new hotness and wire up Code Build and Code Deploy with Code Pipeline and target the EC2 Container Service? Nah, containers is already old school, maybe I should go all in with serverless and use Lambda instead…&lt;/p&gt;

&lt;p&gt;And assuming that I can pick the technologies I want to use, now I’ve got to wrestle with IAM and my VPC settings to get it all working together.&lt;/p&gt;

&lt;p&gt;I have no doubt that Amazon knows that approachability and usability are significant barriers on AWS. They’ve done a lot to improve dashboards, and added smart wizards and getting started guides. But they still seem to struggle with a key idea: introducing &lt;strong&gt;abstractions&lt;/strong&gt;. They need to introduce higher level concepts that hide details underneath them so they can give me a simpler mental model to work with. As it stands I can click the buttons in Code Pipeline to make all the hamsters run, but as soon as I run into a problem I’m back reading the minute rules around IAM policy files.&lt;/p&gt;

&lt;p&gt;In fact it almost seems like there are &lt;strong&gt;no abstractions&lt;/strong&gt; on AWS. (This isn’t quite true - Lambda is a significant one.) But so many of the services include and expose every option, every knob, and every security setting.&lt;/p&gt;

&lt;p&gt;Car manufacturers don’t build cars like those 5000 piece lego sets. They don’t custom design every piece of your car. Much of their manufacturing and design is geared towards designing components they can re-use in multiple vehicle designs. But building on AWS still feels like building that Millennium Falcon…&lt;/p&gt;
</description>
        <pubDate>Fri, 25 Aug 2017 00:07:56 -0700</pubDate>
        <link>http://localhost:4000/2017/08/25/aws-is-a-1000-piece-lego-kit/</link>
        <guid isPermaLink="true">http://localhost:4000/2017/08/25/aws-is-a-1000-piece-lego-kit/</guid>
      </item>
    
      <item>
        <title>Competition vs. collaboration culture</title>
        <description>&lt;p&gt;(Update: Sarah Mei posted a great &lt;a href=&quot;https://twitter.com/sarahmei/status/900456086515335168&quot;&gt;tweetstorm&lt;/a&gt; about how to deliver effective criticism. Very relevant to this topic.)&lt;/p&gt;

&lt;p&gt;One of the enduring management challenges in any engineering group is finding the balance between &lt;em&gt;competition culture&lt;/em&gt; and &lt;em&gt;collaboration culture&lt;/em&gt;. Competition culture is represented by what I think of as the “classic” (or “deplorable”) engineer style: combative, arrogant, and always needing to prove one’s technical ability. Once I had a member like this on a small technical team with me. He was a recent college graduate, and was probably the smartest person in raw intelligence that I ever worked with. Unfortunately the only thing greater than his intelligence was his arrogance. He was &lt;strong&gt;always right&lt;/strong&gt; and you were &lt;strong&gt;always wrong&lt;/strong&gt;. When he finally left the company it was a great relief to the rest of the team.&lt;/p&gt;

&lt;p&gt;Taken to the extreme, this competitive style is pretty obviously detrimental in almost any team setting. However, competition is sometimes quite necessary. Sometimes your team will need to engage a difficult technical problem - one with a high level of ambiguity. In this environment it is important to drive towards the best ideas. I have often counseled engineers that work for me that they need to bring &lt;strong&gt;strong opinions&lt;/strong&gt; to a discussion. They may have the most insight into a problem, and it’s important that they are able to argue their ideas convincingly. It’s very important to demonstrate &lt;em&gt;personal humility&lt;/em&gt; - we all make mistakes (I know I do!) and we’re going to make more in the future. But it’s also important to bring your technical depth and experience to a discussion.&lt;/p&gt;

&lt;p&gt;But many engineers really prefer a culture of collaboration. They place a high premium on getting along effectively, believing that effective collaboration will be key to solving any problem that the team faces. And of course there is significant truth to this. The famous &lt;a href=&quot;https://www.nytimes.com/2016/02/28/magazine/what-google-learned-from-its-quest-to-build-the-perfect-team.html?mcubz=3&quot;&gt;Google team study&lt;/a&gt; determined that &lt;strong&gt;psychological safety&lt;/strong&gt; was the key attribute of effective teams. However, I have seen teams that were simply &lt;strong&gt;too collaborative&lt;/strong&gt;. They placed such value on getting along that they found themselves stuck in the face of hard problems. If the one person with the right answer is unwilling to argue strongly for their approach, then it can leave the team in a state of perpetual deliberation.&lt;/p&gt;

&lt;h2 id=&quot;finding-the-balance&quot;&gt;Finding the balance&lt;/h2&gt;

&lt;p&gt;I try to encourage natural &lt;em&gt;technical leaders&lt;/em&gt; and foster an environment of healthy technical debate. The key insight is to train your &lt;em&gt;competition culture engineers&lt;/em&gt; how to do competition right. Technical discussions should &lt;strong&gt;always&lt;/strong&gt; be grounded in respect for all participants. It’s critical that people leave out personal attacks (“that idea is stupid!”) and work hard to have effective discussions. Here’s a little rulebook that I use with the “competitive” engineers:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Be humble&lt;/strong&gt; - We all have things to learn, and places to improve. And there’s always things to learn from the people you work with. Take those opportunities to learn.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Start by listening&lt;/strong&gt;. Listening well is a skill to master. Work to understand the other perspective on the issue under consideration. You are more likely to convince someone else of your position if they believe you have made a serious attempt to understand theirs.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Improve your emphathy&lt;/strong&gt; Work on getting better at understanding other people’s points of view. Practice putting yourself in someone else’s shoes. Replay their points and arguments to make sure you are understanding where they’re coming from.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Stop trying to be right all the time&lt;/strong&gt;. There are places and settings for in-depth technical arguments, like a scheduled architecture meeting. But daily team chatter in Slack is not the place to constantly prove how smart you are at everyone else’s expense.&lt;/li&gt;
  &lt;li&gt;Recognize that everyone needs psychological safety. This means being careful to recognize and acknowledge your colleagues’ strengths and experience at the same time as you may be disagreeing with them on a point. “I can see lots of situations where that would work, but because of detail XYZ I suspect it will be problematic in our case. I’m happy to discuss further.”&lt;/li&gt;
  &lt;li&gt;Don’t die on every mountain. You will have your areas of expertise, but you don’t need to argue the technical points around everyone else’s expert areas. Pick a limited scope to exercise your technical authority.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Generally the collaborative engineers have less work to do, but I do try to help them see some of the needs and benefits of competition:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Some of our problems are really hard, and at times we will need a vigorous debate to find the best solutions.&lt;/li&gt;
  &lt;li&gt;A key factor for our team velocity is how quickly we can make decisions. If we try to achieve consensus every time we are going to move too slowly.&lt;/li&gt;
  &lt;li&gt;Your colleague almost certainly respects your abilities, but sometimes they will argue in a style that makes it seem like they don’t. Try to engage with them about this directly, and help them to understand how they can improve their interactions.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Finding this balance will help you create teams that can move fast, solve hard problems, and keep everyone happy working together.&lt;/p&gt;
</description>
        <pubDate>Thu, 24 Aug 2017 00:21:40 -0700</pubDate>
        <link>http://localhost:4000/2017/08/24/competition-vs-cooperation-culture/</link>
        <guid isPermaLink="true">http://localhost:4000/2017/08/24/competition-vs-cooperation-culture/</guid>
      </item>
    
      <item>
        <title>Old habits die hard</title>
        <description>&lt;p&gt;I just (re-)committed the cardinal sin of checking some app secrets into a Github repository! I had started a new project and did the usual hacky thing of hard-coding my Oauth client creds into the source code. Then I went ahead and checked it all in… &lt;strong&gt;Whoops!&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Admittedly the repo was private, and the secrets were only Oauth client secrets - easily regenerated. But still. My solution was to remove the secrets from the code, push to a brand new repo, and delete the old repo. Just checking in new clean versions of files obviously doesn’t work since the secrets are still in the git history.&lt;/p&gt;

&lt;p&gt;I probably need to create a new habit of where I store and access secrets. Maybe I’ll try using &lt;a href=&quot;https://www.vaultproject.io/&quot;&gt;Vault&lt;/a&gt; locally and see how that works out.&lt;/p&gt;
</description>
        <pubDate>Mon, 07 Aug 2017 17:07:00 -0700</pubDate>
        <link>http://localhost:4000/2017/08/07/old-habits-die-hard/</link>
        <guid isPermaLink="true">http://localhost:4000/2017/08/07/old-habits-die-hard/</guid>
      </item>
    
      <item>
        <title>Busting the monolith</title>
        <description>&lt;p&gt;It seems that conventional wisdom has coalesced around the idea that large applications should be built as &lt;a href=&quot;https://martinfowler.com/bliki/MonolithFirst.html&quot;&gt;monoliths first&lt;/a&gt;, and then broken down into microservices later. This makes a lot of intuitive sense: start with the easier approach first, and break out services later after your natural &lt;a href=&quot;https://martinfowler.com/bliki/BoundedContext.html&quot;&gt;bounded contexts&lt;/a&gt; are apparent.&lt;/p&gt;

&lt;p&gt;The only problem is that no one really has any good recommendations for exactly &lt;strong&gt;how&lt;/strong&gt; one is supposed to break up a monolith. Sure - identify your bounded contexts and extract services according to the boundaries. That sounds simple enough, but turns out to be really, really hard in practice.&lt;/p&gt;

&lt;h2 id=&quot;the-black-hole&quot;&gt;The black hole&lt;/h2&gt;
&lt;p&gt;One problem with monoliths is that they exert a tremendous amount of gravitational pull on your ongoing engineering efforts. Any attempt to build new features or make changes to existing logic inevitibly turns out to be much, much easier to do inside the monolith than outside. The biggest devlish detail is &lt;em&gt;state&lt;/em&gt;. Suppose I want to make an enhancement to feature A, but all state for feature A is currently stored in the monolith. Now suppose I build my new enhancement as a separate service with its own state. Now I have a synchronization problem to keep my state in sync between the new service and monolith. Moreover, my logic for this feature overall is now split between two different applications, likely leading to bugs and maintenance headaches.&lt;/p&gt;

&lt;p&gt;I can get around this problem by extracting the existing logic into a new service, and then making my enhancements to the extracted service. This sounds great, except that oftentimes the work required to do this extraction will be many times greater than the enhancement work that I need to do. So my message to stakeholders becomes, “I know you want to make these enhancements which will take 3 weeks, but first it’s gonna take us 3 months to extract this new microservice.” Multiply this logic across 4 or 5 different feature areas and you’ve got a very tough sell over the logic of “just add it to the monolith”. I know some organizations get around this problem by doing both: they have Alpha Team work on the service extraction and Beta Team work on the feature enhancement inside the monolith. This is great if you can spare that kind of duplicated effort.&lt;/p&gt;

&lt;h2 id=&quot;its-called-a-tar-ball-for-a-reason&quot;&gt;It’s called a “tar ball” for a reason&lt;/h2&gt;
&lt;p&gt;By far the biggest challenge to extracting services out of your monolith is that fact that your &lt;em&gt;bounded contexts&lt;/em&gt; are very likely a myth. You can draw those boxes on the whiteboard, but most of the time the logic in your monolith is a big ball of twine, with dependencies criss-crossing your code base and database tables. So when you do go to extract your billing logic into a nice, clean independent service, you find that all sorts of other features are woven around that logic. This is the nature of monoliths - clean internal modularity is the rare exception. Remember how we decided we would “start with the monolith” architecture? Well usually that means you are developing fast, without a clear understanding of your service boundaries. And that means it’s highly likely that you’ve got cross-feature dependencies all over the place.&lt;/p&gt;

&lt;p&gt;So now your service extraction actually looks like two projects. First, re-organize the code internal to the monolith to create a properly observed service boundary, and &lt;strong&gt;then&lt;/strong&gt; work to extract that code into a separate service. And by the way, each of those projects is likely gonna take more than a month. So now that feature you planned to implement in 3 weeks isn’t actually gonna get built until next quarter! And in the meantime the engineers are gonna be busy refactoring code and literally building &lt;strong&gt;no new features&lt;/strong&gt;. This is when you get really popular with your PM and Sales teams. Or, you could just keep hacking on the monolith…&lt;/p&gt;

&lt;h2 id=&quot;oh-and-you-need-perfect-tests&quot;&gt;Oh, and you need perfect tests&lt;/h2&gt;
&lt;p&gt;So you’ve decided to extract a service from your monolith. Congratulations! To get some of those great microservice benefits you’ve decided to rewrite your billing logic as a separate service. You go about writing the service, implementing a nice API that mirrors the internal service API you created inside the monolith when you refactored all your pricing logic. But wait. How do you &lt;strong&gt;know&lt;/strong&gt; that the new service implements all the pricing logic in exactly the same way as the old logic? Oh, cause you have unit tests. Good. Except all those tests are structured for the old logic, and they are written in a different language from the new service. Fine, you can just fall back on your exhaustive and complete integration test suite. Right? Right!?!? Oh, you’re integration tests aren’t that great? And they can’t really test all the logic cause your test data doesn’t have the years of acccumulated “real world” data that sits in your production data store? Hmm… that is too bad. And you can’t exactly run the new billing system in parallel with the old code because both systems mutate state all day long. Wow, I guess this is gonna be pretty tricky.&lt;/p&gt;

&lt;h2 id=&quot;lets-get-real&quot;&gt;Let’s get real&lt;/h2&gt;
&lt;p&gt;The fact is, this problem is &lt;strong&gt;really, really&lt;/strong&gt; hard. But people do it. It can be done. But here are some things to think about while you are happily pursuing your &lt;em&gt;monolith first&lt;/em&gt; strategy:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Start thinking about microservices earlier than you think you need to.&lt;/em&gt; A better strategy than “monolith first” might be “microservices as soon as possbile.” As soon as you can start identifying some natural services boundaries then you should probably start investing in breaking a service out of your monolith. The longer you wait the harder it’s gonna be.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Break out a service that requires persistent state.&lt;/em&gt; One of the ways to “cheat” your microservice architecture is to start building new features as stateless services. This gives you logically separate services and multiple code bases, but avoids the really hard data synchronization problems that arise when you are running multiple stateful services. So don’t do that. Make sure that you start building new services that keep their own internal persistent state. This will force you to deal with your data synchronization and eventual consistency problems. You need to exercise that muscle and learn how to do it well if you want your eventual architecture to succeed.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Start refactoring your monolith now.&lt;/em&gt; If you’re monolith is a ball of spagetti, start up a serious project to start refactoring it into separate modules with service boundaries. You will need some application architecture help to enforce the boundaries (Rails and most other frameworks are not gonna do it). Start investing in that now. The sooner you start thinking about “independent services” within your code base the faster you will get to a place where service extraction isn’t a herculean task.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Recognize the anti-patterns in your tooling around the monolith.&lt;/em&gt; As the eng org grows around a monolith you will increasing find the need to create tooling to manage the massive parallel engineering going on in that one code base. Shared dev and testing environments and deployment pipelines become the bottlenecks in monolith development. Fights break out over coding standards and the “best” tools to use. Recognize this pain for what it is: a sign that you’re leeching engineering capacity into managing the monolith. The sooner you recognize this drain the sooner you can justify spending some of that time re-architecting to empower microservice development instead.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And finally, good luck. You’re gonna need it.&lt;/p&gt;
</description>
        <pubDate>Sun, 06 Aug 2017 03:52:00 -0700</pubDate>
        <link>http://localhost:4000/2017/08/06/busting-the-monolith/</link>
        <guid isPermaLink="true">http://localhost:4000/2017/08/06/busting-the-monolith/</guid>
      </item>
    
      <item>
        <title>Evented I/O with Node.js</title>
        <description>&lt;p&gt;Evented I/O with Node.js&lt;/p&gt;

&lt;p&gt;I gave a talk at NodeSummit in February about how we retrofitted our Python code base for Heroku Connect using Node.js to handle evented I/O. Check it out.&lt;/p&gt;
</description>
        <pubDate>Tue, 28 Jul 2015 18:57:00 -0700</pubDate>
        <link>http://localhost:4000/2015/07/28/evented-i-o-with-node-js/</link>
        <guid isPermaLink="true">http://localhost:4000/2015/07/28/evented-i-o-with-node-js/</guid>
      </item>
    
      <item>
        <title>Playing with Spark</title>
        <description>&lt;p&gt;I’ve been playing around with Apache Spark recently and ran into a strange issue the very first time I tried to boot up the Spark Shell:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;java.net.UnknownHostException: spersinger-
ltm1.internal.salesforce.com: spersinger-
ltm1.internal.salesforce.com: nodename nor servname
provided, or not known 
    at java.net.InetAddress.getLocalHost(InetAddress.java:1475)
    Caused by: java.net.UnknownHostException 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Ah, so intuitive! Turns out the problem is described here and the answer was simple. I needed to add an entries to my hosts file mapping the loopback address to my laptop machine name. I guess this is something the JVM expects that isn’t configured automatically by OS X.&lt;/p&gt;
</description>
        <pubDate>Fri, 17 Jul 2015 22:02:00 -0700</pubDate>
        <link>http://localhost:4000/2015/07/17/playing-with-spark/</link>
        <guid isPermaLink="true">http://localhost:4000/2015/07/17/playing-with-spark/</guid>
      </item>
    
      <item>
        <title>Photo Books with Montage</title>
        <description>&lt;p&gt;I’ve finally committed this summer to getting my digital assets in order. This consists of getting everything up on Google Photos, digitizing my numerous old MiniDV tapes from when the kids were young, and finally producing some decent photo books from my vast archive of family pics.&lt;/p&gt;

&lt;p&gt;There’s a million photo book services, including the grandaddy Shutterfly. Most of them have fairly terrible interfaces and appear to produce pedestrian results. Some of the advanced ones have desktop apps that you download and use to construct your book locally (ick!). I tried a couple and they were pretty obtuse. Finally I stumbled on Montage which I’m pretty happy with.&lt;/p&gt;

&lt;p&gt;The killer feature for me with Montage was direct import from Google Photos. This works on an album basis, so my workflow was to create an album in Google Photos with all my source photos and then import this set into Montage.&lt;/p&gt;

&lt;p&gt;What happens after import is really cool. Rather than forcing you to painstakingly layout all your pages, Montage just automatically generates the whole photo book for you. It randomly groups photos into sets and then puts each set onto a page in one of a bunch of different page templates:&lt;/p&gt;

&lt;p&gt;The templates are really nice. All sorts of interesting layouts with matting, insets, and such. Once you have your automatically generated book, then Montage includes a nice editor where you can re-arrange photos, add text, and even change the page template.&lt;/p&gt;

&lt;p&gt;All told it took me about an hour to create a 20 page book with about 50 photos. I finalized my purchase and waited for the result. The final book is really nice quality. Great cover, and photos almost bleed all the way to the edge.&lt;/p&gt;

&lt;p&gt;My only complaint is that large photos in the book seemed to have pretty poor resolution. I don’t know if this is some problem with the quality of the imported files from Google, a problem with the Montage production system, or just a limitation of my original photos. I did order the largest size book (12”x12”) so I’m sure that contributed. Also, the final book cost about $150 which is pretty pricey - I’m sure its more than other competing services. However, the middle size (8.5”) is only $79, so I’ll probably get that one next time and see how it goes.&lt;/p&gt;
</description>
        <pubDate>Thu, 16 Jul 2015 22:05:00 -0700</pubDate>
        <link>http://localhost:4000/2015/07/16/photo-books-with-montage/</link>
        <guid isPermaLink="true">http://localhost:4000/2015/07/16/photo-books-with-montage/</guid>
      </item>
    
      <item>
        <title>Software cohesion and it’s organizational impact</title>
        <description>&lt;p&gt;The typical software company builds and maintains a single, monolithic tarball of code. Certainly this is true for most startups. And if your startup becomes successful then eventually the high cohesion within that code base will make it tremendously hard to keep innovating your product. This is the point when many companies launch efforts to attempt to start breaking down the monolith into separately maintainable services (i.e. ‘micro services’).&lt;/p&gt;

&lt;p&gt;That effort is necessary, but very painful. While it’s going on it becomes really difficult to continue to innovate in your product, because not only is the effort consuming a lot of engineering resources, but the nature of the effort (refactoring functionality out into separate services) runs counter to any efforts to improve or change the product. I have heard of at least one major vendor which launched no new features for 12 months while a large refactoring was completed.&lt;/p&gt;

&lt;p&gt;The good news about this process is that it generally mirrors what’s happening organizationally in your engineering team. The team is transitioning from single logical entity to multiple distributed teams.&lt;/p&gt;

&lt;p&gt;But what if you built things the right way from the start? When I joined Heroku I learned that the Heroku platform was built from micro services almost from the start. And our engineering team reflects that low cohesion — we have lots of small, autonomous teams. There is no monolith for us to break up.&lt;/p&gt;

&lt;p&gt;But not surprisingly, we now have a distributed systems challenge writ large. Not only do we have to worry about runtime coordination amongst a large number of independent services, but we have to coordinate the work of a large number of small teams. Mostly those teams can execute independently, but launching features that cross functional teams requires coordination. Resource allocation is also challenging. Smaller, independent teams makes it harder for developers to move across subsystems. Allocating new headcount is similarly difficult because every team feels like it needs “just one more person”.&lt;/p&gt;

&lt;p&gt;One solution to this problem is to inject some cohesion into the system. That is, group multiple teams into larger entities that have internal cohesion and expose a single “management API” to the rest of the org. We are also experimenting with feature teams, eng groups that own and develop an entire feature-set across systems.&lt;/p&gt;

&lt;p&gt;One of our best approaches is to try to standardize our frameworks and tooling for building, deploying, and integrating new services. This helps make new service development much closer to traditional new module development for a monolithic application. Netflix and Amazon are leaders in this kind of effort and their long experience offers a lot of wisdom for organizations looking to build with a micro services approach.&lt;/p&gt;
</description>
        <pubDate>Sat, 23 May 2015 22:18:00 -0700</pubDate>
        <link>http://localhost:4000/2015/05/23/software-cohesion-and-its-organizational-impact/</link>
        <guid isPermaLink="true">http://localhost:4000/2015/05/23/software-cohesion-and-its-organizational-impact/</guid>
      </item>
    
      <item>
        <title>Self-hosting</title>
        <description>&lt;p&gt;Truly, the perennial question, is where to host my blog? Having been through Blogger, Wordpress and Tumblr, I think I’ve finally realized that you’ve got to host it yourself. So I’m trying out Ghost which is very much au currant with the Hacker News kids these days. Naturally I’m hosting on Heroku. I recommend trying out the “Heroku Button” for one-click install of Ghost. It don’t get any easier than that!&lt;/p&gt;

&lt;p&gt;Ghost is a very cool, open source blogging app written in Node.js. I have it running using Postgres for persistence and Amazon S3 for asset storage. The basic steps to getting everything running were pretty easy:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Create new Heroku app via Ghost Heroku Button&lt;/li&gt;
  &lt;li&gt;Use heroku git:clone to pull down the code locally, then install a theme package into the content/themes directory. I’m using Ghostium at the time of writing.&lt;/li&gt;
  &lt;li&gt;Do git push heroku master to deploy the code with theme.&lt;/li&gt;
  &lt;li&gt;Setup my config vars for S3 access using heroku config:set. This restarts the app automatically.&lt;/li&gt;
  &lt;li&gt;Visit the Ghost admin panel to configure settings.&lt;/li&gt;
  &lt;li&gt;Upload a home page image and whatnot.&lt;/li&gt;
  &lt;li&gt;Tear hair out for 30 minutes configuring g#da!!m public access on the S3 bucket including CORS.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The hardest part, by far, was getting the S3 bucket configured correctly. It makes sense that AWS locks down bucket access by default, but cutting-and-pasting XML config files into the AWS console is definitely not the “developer experience” one hopes to have in 2015. For your copy-and-paste pleasure here are the settings I configured:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Bucket policy
{ 
    &quot;Version&quot;: &quot;2008-10-17&quot;,
    &quot;Statement&quot;: [
        {
            &quot;Sid&quot;: &quot;AllowPublicRead&quot;,
            &quot;Effect&quot;: &quot;Allow&quot;,
            &quot;Principal&quot;: {
                &quot;AWS&quot;: &quot;&quot;
            },
            &quot;Action&quot;: &quot;s3:GetObject&quot;,
            &quot;Resource&quot;: &quot;arn:aws:s3:::scottp.blog/&quot;
        }
    ]
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;CORS&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cp&quot;&gt;&amp;lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;CORSConfiguration&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;xmlns=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;http://s3.amazonaws.com/doc/2006-03-01/&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;CORSRule&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;AllowedOrigin&amp;gt;&lt;/span&gt;https://scottpblog.herokuapp.com&lt;span class=&quot;nt&quot;&gt;&amp;lt;/AllowedOrigin&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;AllowedMethod&amp;gt;&lt;/span&gt;GET&lt;span class=&quot;nt&quot;&gt;&amp;lt;/AllowedMethod&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;MaxAgeSeconds&amp;gt;&lt;/span&gt;3000&lt;span class=&quot;nt&quot;&gt;&amp;lt;/MaxAgeSeconds&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;AllowedHeader&amp;gt;&lt;/span&gt;Content-&lt;span class=&quot;nt&quot;&gt;&amp;lt;/AllowedHeader&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;AllowedHeader&amp;gt;&lt;/span&gt;Host&lt;span class=&quot;nt&quot;&gt;&amp;lt;/AllowedHeader&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/CORSRule&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;CORSRule&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;AllowedOrigin&amp;gt;&lt;/span&gt;https://scottpblog.herokuapp.com&lt;span class=&quot;nt&quot;&gt;&amp;lt;/AllowedOrigin&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;AllowedMethod&amp;gt;&lt;/span&gt;GET&lt;span class=&quot;nt&quot;&gt;&amp;lt;/AllowedMethod&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;MaxAgeSeconds&amp;gt;&lt;/span&gt;3000&lt;span class=&quot;nt&quot;&gt;&amp;lt;/MaxAgeSeconds&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;AllowedHeader&amp;gt;&lt;/span&gt;Content-&lt;span class=&quot;nt&quot;&gt;&amp;lt;/AllowedHeader&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;AllowedHeader&amp;gt;&lt;/span&gt;Host&lt;span class=&quot;nt&quot;&gt;&amp;lt;/AllowedHeader&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/CORSRule&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/CORSConfiguration&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And yes, I had to HTML escape all that config to paste it into the Ghost markdown editor. You’re welcome.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Update&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Don’t forget to schedule automatic backups for your Postgres database on Heroku:&lt;/p&gt;

&lt;p&gt;$ heroku pg:backups schedule –at ‘04:00 UTC’ DATABASE_URL&lt;/p&gt;
</description>
        <pubDate>Thu, 21 May 2015 22:08:00 -0700</pubDate>
        <link>http://localhost:4000/2015/05/21/self-hosting/</link>
        <guid isPermaLink="true">http://localhost:4000/2015/05/21/self-hosting/</guid>
      </item>
    
      <item>
        <title>Python Profiling made easy</title>
        <description>&lt;p&gt;This is more a reminder to myself of how to use the basic Python library’s tools for profiling.&lt;/p&gt;

&lt;p&gt;Say you’ve got a nice function which is running slow:&lt;/p&gt;

&lt;p&gt;object1.do_slow_stuff()
You can generate the profile data easily enough:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import cProfile
cProfile.runctx(“object1.do_slow_stuff()”, globals(), locals(), “profdata”)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;If you don’t use the &lt;code class=&quot;highlighter-rouge&quot;&gt;runctx&lt;/code&gt; version you can run into trouble in iPython finding variables defined at the repl prompt.&lt;/p&gt;

&lt;p&gt;Now to analyze you’re results:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import pstats
p = pstats.Stats(“profdata”)
To print a list of functions taking the most time, try this:

p.sort_stats(‘cumulative’).print_stats(10)
  ncalls  tottime  percall  cumtime  percall filename:lineno(function)

        1    0.000    0.000   16.435   16.435 /celery/app/task.py:322(__call__)

        1    0.000    0.000   16.435   16.435 /mirror/tenant_actions.py:324(poll_db_task)

        5    0.002    0.000   16.427    3.285 /mirror/sync_machine.py:812(poll_database)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;That says, “sort the stats by cumulative time spent inside each function and print the top 10”. Now what you’re looking for is when you have a big drop in total time. Like this:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    4    0.083    0.021   15.117    3.779 /lib/sf_adapter.py:1079(_process_data_change)    

    4    0.000    0.000    8.292    2.073 /lib/sf_adapter.py:89(update)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;So there were 4 calls to _process_data_change which took 3.7 secs. This function (probably) called “update”, which constituted 2 secs, but that still leaves 1.7 secs doing something else. To figure out what that “something else” is, we can ask pstats for the functions that our “processdata_change” function called:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;p.strip_dirs().print_callees(“_process_data_change”)

ncalls  tottime  cumtime

800    0.005    0.898  base.py:116(generateObject)

800    0.011    0.187  copy.py:145(deepcopy)

800    0.001    0.001  data_change.py:82(setSfId)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This shows us the time spent in each function called by the original one, and helps us spot which subroutines are the most expensive.&lt;/p&gt;
</description>
        <pubDate>Wed, 09 Oct 2013 22:07:00 -0700</pubDate>
        <link>http://localhost:4000/2013/10/09/python-profiling-made-easy/</link>
        <guid isPermaLink="true">http://localhost:4000/2013/10/09/python-profiling-made-easy/</guid>
      </item>
    
      <item>
        <title>Installing Mysql-Python 1.2.4b4 on Mac OS X Lion</title>
        <description>&lt;p&gt;My new service idea for the day is an online service which installs Mysql and all the right client libraries for you automatically. Would I pay $20 for that every time I got a new computer - for sure.&lt;/p&gt;

&lt;p&gt;Here are the steps I followed to do it manually. Note that these are instructions for install the Mysql 1.2.4 package which is required to use SSL to connect to RDS. You need to download the package first:&lt;/p&gt;

&lt;p&gt;Install Mysql 64 Bit package from Sun
export PATH=$PATH:/usr/local/mysql/bin
export DYLD_LIBRARY_PATH=/usr/local/mysql/lib/
export VERSIONER_PYTHON_PREFER_64_BIT=yes
export VERSIONER_PYTHON_PREFER_32_BIT=no
pip install ./pip/MySQL-python-1.2.4b4
Make sure to add DYLD_LIBRARY_PATH to your permanent environment.&lt;/p&gt;

</description>
        <pubDate>Mon, 19 Aug 2013 22:12:00 -0700</pubDate>
        <link>http://localhost:4000/2013/08/19/installing-mysql-python-1-2-4b4-on-mac-os-x-lion/</link>
        <guid isPermaLink="true">http://localhost:4000/2013/08/19/installing-mysql-python-1-2-4b4-on-mac-os-x-lion/</guid>
      </item>
    
      <item>
        <title>Fun with RabbitMQ</title>
        <description>&lt;p&gt;I’ve been using a Rabbit MQ in anger these days at my latest startup. It’s anchoring a large async, distributed system we’re building. I’ve taken to saying about Rabbit: “When it’s working, I love it. When it’s not, there’s nothing I hate more”.&lt;/p&gt;

&lt;p&gt;The first big issue we ran into was using rabbit over SSL. The issue wasn’t with rabbit the server, but rather finding a python client that worked with both Celery (which is awesome) and Rabbit over SSL. With some judicious hacking on Kombu we got it working.&lt;/p&gt;

&lt;p&gt;As an aside, one issue that vexed us for a number of hours was the failure to connect to rabbit over ssl when running on Heroku, even though everything ran fine locally. Turns out the issue came from the fact that opening the first socket connection from your Heroku app can take up to 10 seconds, and thus our rabbit connection was timing out. Upping the timeout got around this problem.&lt;/p&gt;

&lt;p&gt;My current bedevilment comes from an issue that I see fairly frequently during development. The issue is that if you’re rabbit client doesn’t cleanly close its connection (like it may if you hit Ctrl-C to stop it), then you may end up with “phantom” rabbit connections/consumers. It seems that rabbit can take a long time (like multiple minutes) to decide that these consumers are really gone.&lt;/p&gt;

&lt;p&gt;In the meantime, rabbit will attempt to deliver messages to clients which have disconnected. This can be really disconcerting, because the symptom is that you publish a message to the broker, and then it disappears. If you do connect a consumer to the broker, it may receive some of your messages, and eventually they will all be delivered, but it can take minutes for that to happen, which feels like an eternity when you’re sitting there waiting for your program to do something!&lt;/p&gt;

&lt;p&gt;So first, some hints on figuring out what’s going on. First of all, you can list the current client connections to your broker:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;
sudo rabbitmqctl list_connections pid name vhost&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&amp;lt;rabbit@rabbit1.2.18388.5&amp;gt; 10.141.128.228:36052 -&amp;gt; 10.70.70.119:5671 qa
&amp;lt;rabbit@rabbit1.2.18460.5&amp;gt; 10.87.109.52:39282 -&amp;gt; 10.70.70.119:5671 qa
&amp;lt;/code&amp;gt;&lt;/p&gt;

&lt;p&gt;If you see lots more connections that you think you actually have active, then you know you’ve got a problem. You can also see how many un’acked messages you’ve got lying around:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;
sudo rabbitmqctl list_queues -p dev2 name consumers messages_unacknowledged owner_pid
List queues…
queue1  0      4
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;So now we can clearly see we have un’acked messages sitting there. To cleanup, it is possible to force close our phantom connections like this:
&lt;code&gt;sudo rabbitmqctl close_connection “&amp;lt;rabbit@rabbit1.2.22974.4&amp;gt;” “die”
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;This will force close the connection, although it can take a while (like a few seconds) for it to actually happen. If you close all your connections like this, and then re-connect your client, then it will suddenly receive all the un’acked messages.&lt;/p&gt;

&lt;p&gt;I don’t know offhand if this phantom connection problem is made worse by using SSL, although I believe I saw it even over non-SSL connections. But clearly the big message is, make sure you’re closing your rabbit connections properly. 
Good times.&lt;/p&gt;

&lt;p&gt;Published on October 26, 2012&lt;/p&gt;

</description>
        <pubDate>Fri, 26 Oct 2012 22:14:00 -0700</pubDate>
        <link>http://localhost:4000/2012/10/26/fun-with-rabbitmq/</link>
        <guid isPermaLink="true">http://localhost:4000/2012/10/26/fun-with-rabbitmq/</guid>
      </item>
    
      <item>
        <title>The death of APIs</title>
        <description>&lt;p&gt;There’s been much gnashing of teeth over Twitter’s continued moves to restrict use of its APIs as an application platform. But really Twitter is just continuing a much larger trend of big companies eliminating or reducing access to their APIs.&lt;/p&gt;

&lt;p&gt;Search APIs are a great example. A few years ago you could get free (or at least a generous free tier) access to Google and Yahoo search APIs. But now these APIs are gone. Bing still has a search API but it is quite expensive ($1000/mo for 500k requests). Google in particular has posted whole blog posts about APIs they are deprecating. Sure, it makes sense to deprecate APIs for products you’re dropping, but how do you explain web search and image search?&lt;/p&gt;

&lt;p&gt;I think we went through a few years of API mania where everybody and their brother was publishing a free API and exhorting developers to jump on board. But I think we’re going to look back and realize there was a bit of hysteria at play. APIs have always been about enhancing the value of your platform by getting other people to build features for you. But companies don’t provide APIs out of altruism, and as we’ve seen, they will feel no compunction to remove or restrict those APIs when the business case changes.&lt;/p&gt;

&lt;p&gt;So the lesson is, be careful who’s API you’re using. You should understand the business case for why that API exists, and understand your risks of losing access to it.&lt;/p&gt;

&lt;p&gt;One important question to ask: Is this API for a product that is explicitly position as a platform? Platforms provide a generic substrate for building applications. Their raison d’être is to provide services through APIs. Platform vendors have the strongest reasons for providing API access. But there’s lots of APIs for end user products. Picasa (Google photos), for example, provides various APIs, but it is also its own product designed for the end user. It’s dangerous to use product APIs because the value of the underlying product is much less dependent on third party applications.&lt;/p&gt;

&lt;p&gt;This is the mistake that Twitter API users have been making. The hacker community wants Twitter to be a platform. But that doesn’t make it so. Twitter has always been an end user product, and it’s value as a platform was never particularly clear. This dynamic is just as true for Facebook, I just think a lot more people realize it in that case. Everyone already understands that the Facebook “platform” is a marketing device, and that betting your company on that platform carries a high risk.&lt;/p&gt;

&lt;p&gt;When your using some API, you should understand that both companies are getting value from your use of the API. You are getting a valuable service and oftentimes easy access to an installed customer base, and in exchange you are making someone else’s platform more valuable. Pinterest and Instagram would almost certainly not have grown so fast without the use of the Facebook social graph. And in return they have reinforced the value of that graph and its exclusivity to Facebook.&lt;/p&gt;

&lt;p&gt;But business conditions change, and what made sense yesterday is just one pivot or re-org away from not making sense today. It’s always good to have a backup plan.&lt;/p&gt;
</description>
        <pubDate>Sun, 26 Aug 2012 22:16:00 -0700</pubDate>
        <link>http://localhost:4000/2012/08/26/untitled/</link>
        <guid isPermaLink="true">http://localhost:4000/2012/08/26/untitled/</guid>
      </item>
    
      <item>
        <title>Dependency injection in PHP is a really bad idea</title>
        <description>&lt;p&gt;I’m not a huge fan of dependency injection. Anytime you move logic out of code and into some XML file you’re making your application harder to understand.&lt;/p&gt;

&lt;p&gt;The argument for dependency injection is that it makes your application more flexible by creating a loose coupling between components. So rather than having a hard-coded line of code to instantiate a concrete instance of some logger class, instead you move the type choice out into some configuration file.&lt;/p&gt;

&lt;p&gt;Dependency injection was popularized by the Spring framework in Java. Now I can almost, sort of, see the benefit of DI when using Java, where the compile-jar-startup cycle can be quite long. (Although I think most cases are probably better handled by a basic factory pattern.) When you’re using a static-typed language like Java, then DI can introduce some late binding where types don’t have to be resolved until runtime.&lt;/p&gt;

&lt;p&gt;But recently I’ve gotten the peculiar pleasure of getting to work on a PHP application using the Symfony 2 framework. Symfony includes a DI system taking inspiration from Spring. They even have a really nice web page describing the system, which includes this great feature: “comes bundled with a Graphviz dumper, allowing you to visualize the graph of your objects and ease the debugging of your container”.&lt;/p&gt;

&lt;p&gt;The only problem is that dependency injection is a terrible idea in PHP. After all, PHP is a loosely typed, dynamic language. If you want to use a different class for your logger, well then you just assign your “logger” variable to some other object. Objects are duck-typed in PHP, you can call “logMessage” on any old object you like. There’s no compile-link-debug cycle to avoid by moving type resolution into some XML file!!&lt;/p&gt;

&lt;p&gt;You want to choose a different logger at runtime? Just set some config option (say in php.ini or your own config system or in an env variable) and choose your logger class at runtime based on the config value. You can even put the logger class name in your config, and use: “$logger = new $loggerClassName;”. Please, please, do not start littering your code with XML files, and forcing yourself to “visualize the graph of your objects to ease debugging of your container”!!&lt;/p&gt;

&lt;p&gt;Dependency injection is a crummy solution to a problem specific to the limitations of complex, statically-typed systems. It really has no benefit in a dynamic language like PHP.&lt;/p&gt;
</description>
        <pubDate>Thu, 12 Jan 2012 22:17:00 -0800</pubDate>
        <link>http://localhost:4000/2012/01/12/dependency-injection-in-php-is-a-really-bad-idea/</link>
        <guid isPermaLink="true">http://localhost:4000/2012/01/12/dependency-injection-in-php-is-a-really-bad-idea/</guid>
      </item>
    

    
      
        
      
    
      
        
          <item>
            <title>About</title>
            <description>&lt;p&gt;My name is Scott Persinger, and this blog collects some of my personal and professional reflections. I am a Bay Area native, married father of three. I was a co-founder at Alier, Remixation, and Cloudconnect. More recently I held engineering leadership positions at Stripe and Heroku.&lt;/p&gt;
</description>
            <link>http://localhost:4000/about.html</link>
          </item>
        
      
    
      
    
      
    
      
        
          <item>
            <title>Style Guide</title>
            <description>At [Aspire Themes](http://aspirethemes.com/) I use a lot of tools to help me create WordPress, Ghost and Jekyll themes. Tools will range from development, design, services, hosting and automation.

Graphic design is the paradise of individuality, eccentricity, heresy, abnormality, hobbies, and humors. - George Santayana.

---

# Simple default styles for headings

## Simple default styles for headings

### Simple default styles for headings

#### Simple default styles for headings

##### Simple default styles for headings

###### Simple default styles for headings

---

* Ut at interdum nunc. Maecenas commodo turpis quis elementum gravida.
* Nunc ac sapien tellus. Quisque risus enim, tempus eget porttitor.
* Donec nibh massa, rutrum a sollicitudin eu, lacinia in lorem.

---

1. Ut at interdum nunc. Maecenas commodo turpis quis elementum gravida.
2. Nunc ac sapien tellus. Quisque risus enim, tempus eget porttitor in.
3. Donec nibh massa, rutrum a sollicitudin eu.

---

&gt; Graphic design is the paradise of individuality, eccentricity, heresy, abnormality, hobbies, and humors. - George Santayana

---

{% highlight js %}
'use strict';
var markdown = require('markdown').markdown;
function Editor(input, preview) {
  this.update = function() {
    preview.innerHTML = markdown.toHTML(input.value);
  };
  input.editor = this;
  this.update();
}
{% endhighlight %}

You can add inline code just like this, E.g. `.code { color: #fff; }`

{% highlight css %}
pre {
  background-color: #f4f4f4;
  max-width: 100%;
  overflow: auto;
}
{% endhighlight %}

---

Cras sed sodales enim. Duis nec erat magna. Sed scelerisque pretium mi et [unsplash](https://unsplash.com/) ullamcorper mauris aliquam ornare fringilla. In luctus commodo quam eget posuere.

---

&lt;iframe src=&quot;https://player.vimeo.com/video/97202679&quot; frameborder=&quot;0&quot; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;

---

&lt;iframe src=&quot;https://embed.ted.com/talks/ted_halstead_a_climate_solution_where_all_sides_can_win&quot; width=&quot;640&quot; height=&quot;360&quot; frameborder=&quot;0&quot; scrolling=&quot;no&quot; allowfullscreen&gt;&lt;/iframe&gt;

---

&lt;iframe width=&quot;100%&quot; height=&quot;166&quot; scrolling=&quot;no&quot; frameborder=&quot;no&quot; src=&quot;https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/29738591&amp;amp;color=ff5500&amp;amp;auto_play=false&amp;amp;hide_related=false&amp;amp;show_comments=true&amp;amp;show_user=true&amp;amp;show_reposts=false&quot;&gt;&lt;/iframe&gt;

---

&lt;p data-height=&quot;265&quot; data-theme-id=&quot;light&quot; data-slug-hash=&quot;YWvpRo&quot; data-default-tab=&quot;css,result&quot; data-user=&quot;kharrop&quot; data-embed-version=&quot;2&quot; data-pen-title=&quot;Referral Form&quot; class=&quot;codepen&quot;&gt;See the Pen &lt;a href=&quot;http://codepen.io/kharrop/pen/YWvpRo/&quot;&gt;Referral Form&lt;/a&gt; by Kelly Harrop (&lt;a href=&quot;http://codepen.io/kharrop&quot;&gt;@kharrop&lt;/a&gt;) on &lt;a href=&quot;http://codepen.io&quot;&gt;CodePen&lt;/a&gt;.&lt;/p&gt;
&lt;script async src=&quot;https://production-assets.codepen.io/assets/embed/ei.js&quot;&gt;&lt;/script&gt;

---

![about](/images/pages/about.jpeg)

---

&lt;input type=&quot;text&quot; placeholder=&quot;I'm an input field!&quot;&gt;

---

&lt;button class='c-btn c-btn--small'&gt;Button&lt;/button&gt;

&lt;button class='c-btn'&gt;Button&lt;/button&gt;

&lt;button class='c-btn c-btn--full'&gt;Button&lt;/button&gt;

{% highlight html %}
&lt;button class='c-btn c-btn--small'&gt;Button&lt;/button&gt;
&lt;button class='c-btn'&gt;Button&lt;/button&gt;
&lt;button class='c-btn c-btn--full'&gt;Button&lt;/button&gt;
{% endhighlight %}
</description>
            <link>http://localhost:4000/style-guide.html</link>
          </item>
        
      
    
      
    

  </channel>
</rss>